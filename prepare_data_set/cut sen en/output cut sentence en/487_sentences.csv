This research proposes model-based reinforcement learning (MBRL) for planar motion control of 2-DOF and 3-DOF robotic arms.
"Three case studies - placing task, 2-DOF and 3-DOF reaching tasks - are used as test problems."
The 2-DOF and 3-DOF reaching tasks were investigated with additional noise in motion control signal and different training techniques.
"Within MBRL, 3 machine learning regression techniques, Gaussian process regression (GPR), artificial neural network (ANN) and support vector regression (SVR) were used to create environment model and then combined with an optimization algorithm, covariance matrix adaptation evolution strategy (CMA-ES)."
They were also benchmarked with the standard technique inverse kinematics (IK).
The results show that MBRL with GPR and CMA-ES has the highest performance against the other 3 techniques.
"Since GPR is approximating covariance that considered noise, therefore, its success rates, which are 100%, 96-100% and 98-100% success rate in placing task, 2-DOF and 3-DOF reaching task respectively, was higher than those of ANN, SVR and IK, obviously."
"Although GPR spent the most training time, GPR was more suitable than other techniques of which the approximately average success rate was only 50%."
